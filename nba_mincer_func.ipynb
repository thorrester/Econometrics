{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sjf2gg2/opt/anaconda3/envs/tf/lib/python3.7/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import requests\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "import itertools\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "# This imports the client\n",
    "from basketball_reference_web_scraper import client\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Functions##################\n",
    "\n",
    "def make_soup(url):\n",
    "    comm = re.compile(\"<!--|-->\")\n",
    "    page = urlopen(url)\n",
    "    soupdata = BeautifulSoup(comm.sub(\"\", page.read().decode('utf-8')), 'lxml')\n",
    "    return soupdata\n",
    "\n",
    "def advanced_data(start_year, end_year):\n",
    "    \"\"\"Scrapes basketball reference site for advance data given the year ranges\"\"\"\n",
    "    dfs=[]\n",
    "    for year in range(start_year, end_year+1):\n",
    "        stats = client.players_advanced_season_totals(season_end_year=year)\n",
    "        df = pd.DataFrame(stats)\n",
    "        df['year']=year\n",
    "        dfs.append(df)\n",
    "    concat = pd.concat(dfs, ignore_index=True)\n",
    "    names = concat['slug'].unique()\n",
    "    \n",
    "    return concat, names\n",
    "\n",
    "def player_salaries(name_list):\n",
    "    \"\"\"Using a name list, this function scrapes basketball reference for salary informatin and returns the list of dataframes\"\"\"\n",
    "    dfs=[]\n",
    "    name_count = 0\n",
    "    for name in names:\n",
    "        salary_dict = {}\n",
    "        salary_dict['slug'] = []\n",
    "        salary_dict['year'] = []\n",
    "        salary_dict['team'] = []\n",
    "        salary_dict['salary'] = []\n",
    "        try:\n",
    "            url =f'https://www.basketball-reference.com/players/{name[0]}/{name}.html'\n",
    "            response = requests.get(url=url,verify=False)\n",
    "            soup=make_soup(url)\n",
    "            tableStats = soup.find_all('table', {'id':'all_salaries'})\n",
    "        except Exception:\n",
    "            print(f'could not make soup for {name}')\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            res = []\n",
    "            for tr in tableStats:\n",
    "                td = tr.find_all('td')\n",
    "                row = [tr.text.strip() for tr in td if tr.text.strip()]\n",
    "                if row:\n",
    "                    res.append(row)\n",
    "                th = tr.find_all('th')\n",
    "                row = [tr.text.strip() for tr in th if tr.text.strip()]\n",
    "                if row:\n",
    "                    res.append(row)\n",
    "        except Exception:\n",
    "            print(f'could not parse table for {name}')\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            yrs = len(res[1])\n",
    "            \n",
    "            #Assert these are the same\n",
    "            #len(range(4,yrs-1))==len(range(0,yrs-5))\n",
    "            \n",
    "            for i in range(4,yrs-1):\n",
    "                salary_dict['slug'].append(name)\n",
    "                salary_dict['year'].append(res[1][i])\n",
    "\n",
    "            count = 0    \n",
    "            for i in range(0,yrs-5):\n",
    "                salary_dict['team'].append(res[0][0+count])\n",
    "                salary = int(res[0][2+count].strip('$').replace(',', ''))\n",
    "                salary_dict['salary'].append(salary)\n",
    "                count+=3\n",
    "        except Exception:\n",
    "            print(f'could not create the dict for {name}')\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            df = pd.DataFrame(salary_dict)\n",
    "            dfs.append(df)\n",
    "        except Exception:\n",
    "            print(f'could not convert {name} to dataframe')\n",
    "            continue\n",
    "        if name_count % 100 == 0:\n",
    "            print(name_count)\n",
    "            name_count+=1\n",
    "        else:\n",
    "            name_count+=1\n",
    "    return dfs\n",
    "\n",
    "def positions(position_list):\n",
    "    \"\"\"Cleans the dataframe position information column and returns only the position\"\"\"\n",
    "    positions = []\n",
    "    for i in range(0,len(position_list)):\n",
    "        text = str(position_list[i])\n",
    "        m = re.search('<Position.(.*): ', text)\n",
    "        result = m.group(1)\n",
    "        positions.append(result)\n",
    "    position_list = pd.DataFrame({'positions':sorted(positions)})\n",
    "    \n",
    "    return position_list\n",
    "\n",
    "def clean_names(team_name_list):\n",
    "    \"\"\"Given a list of team names, this function cleans the text and returns only the team names\"\"\"\n",
    "    team_list = []\n",
    "    try:\n",
    "        for i in range(0,len(team_name_list)):\n",
    "            text = str(team_name_list[i])\n",
    "            m = re.search('Team.(.*)', text)\n",
    "            result = m.group(1)\n",
    "            team_list.append(result)\n",
    "        team_list = pd.DataFrame({'team_df':sorted(team_list)})\n",
    "    except:\n",
    "        team_list = pd.DataFrame({'team_df':sorted(team_name_list)})\n",
    "\n",
    "    return team_list\n",
    "\n",
    "def clean_salary_names(team_name_list):\n",
    "    \"\"\"Removes old team names and keeps the most current teams\"\"\"\n",
    "    sal_teams = pd.DataFrame({'sal_team':sorted(team_name_list)})\n",
    "    remove_teams = ['New Orleans/Oklahoma City Hornets', 'Seattle SuperSonics', 'Vancouver Grizzlies','Washington Bullets']\n",
    "    sal_teams = sal_teams.loc[~sal_teams['sal_team'].isin(remove_teams)].reset_index(drop=True)\n",
    "    return sal_teams\n",
    "\n",
    "def experience(df, name_list):\n",
    "    \"\"\"Calculates the experience in years for each player\"\"\"\n",
    "    exp_dfs=[]\n",
    "    for name in name_list:\n",
    "        subset = df.loc[df['slug'] == name]\n",
    "        subset['min_year'] = min(subset['year'])-1\n",
    "        subset['exp'] = subset['year']-subset['min_year']\n",
    "        exp_dfs.append(subset)\n",
    "    exp_df = pd.concat(exp_dfs, ignore_index=True)\n",
    "    return exp_df\n",
    "\n",
    "def linear_regression_combos(fixed_y, fixed_X, variables_to_test, categorical_variables, dataframe):\n",
    "    \"\"\"\n",
    "    Runs a linear regression on fixed y and x variables along with different combonations of other variables.\n",
    "    Returns a dataframe of variable combonations and their resulting RMSE scores.\n",
    "    \"\"\"\n",
    "    \n",
    "    combos = []\n",
    "    for length in range(0, 6):\n",
    "        for subset in itertools.combinations(variables_to_test, length):\n",
    "            combos.append(np.asanyarray(subset))\n",
    "            \n",
    "    combos_with_fixed = [combo.tolist() + fixed_X for combo in combos]\n",
    "    \n",
    "    ##### Regression #####\n",
    "    y = dataframe[fixed_y]\n",
    "    \n",
    "    results = {}\n",
    "    results['combos'] = []\n",
    "    results['R2'] = []\n",
    "    results['R2_adj'] = []\n",
    "    results['RMSE'] = []\n",
    "    for combo in combos_with_fixed:\n",
    "\n",
    "        X = dataframe[combo]\n",
    "        cat =[]\n",
    "        for i in combo:\n",
    "            if i in categorical_variables:\n",
    "                cat.append(i)\n",
    "            \n",
    "        if len(cat) >=1:\n",
    "            X = pd.get_dummies(X, columns=cat, drop_first=True)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "        X = sm.add_constant(X.values)\n",
    "        res = sm.OLS(y,X).fit()\n",
    "        mse = np.divide(np.sum(np.square(res.resid)),len(data['log_sal']))\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        results['combos'].append(combo)\n",
    "        results['R2'].append(np.round(res.rsquared,3))\n",
    "        results['R2_adj'].append(np.round(res.rsquared_adj,3))\n",
    "        results['RMSE'].append(np.round(rmse,3))\n",
    "       \n",
    "    df = pd.DataFrame(results).sort_values(by='RMSE', ascending=True)\n",
    "    return df, combos_with_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Misc stuff ################\n",
    "years_df = pd.DataFrame({'year_range': ['1999-00','2000-01','2001-02','2002-03','2003-04','2004-05','2005-06','2006-07','2007-08','2008-09','2009-10','2010-11','2011-12','2012-13','2013-14','2014-15','2015-16','2016-17','2017-18','2018-19','2019-20'],\n",
    "                         'year': [2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020]})\n",
    "\n",
    "all_stars = pd.read_csv('nba_allstars_10-18.csv',names=['player','allstar','year'],engine='python',header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_stats, names = advanced_data(2010,2018)\n",
    "\n",
    "#Clean position infor\n",
    "position_list = list(adv_stats['positions'])\n",
    "adv_stats['positions']=positions(position_list)\n",
    "\n",
    "#clean team info\n",
    "teams= list(adv_stats['team'])\n",
    "adv_stats['team'] = clean_names(teams)\n",
    "\n",
    "#Create the join table for team info\n",
    "adv_stats_team_names = list(adv_stats['team'].unique())\n",
    "adv_team_names_cleaned = clean_names(adv_stats_team_names)\n",
    "\n",
    "# Get unique team names from salary data df\n",
    "salaries = player_salaries(names)\n",
    "salary_df = pd.concat(salaries, ignore_index=True)\n",
    "sal_team_names = salary_df['team'].unique()\n",
    "sal_team_names_cleaned = clean_salary_names(sal_team_names)\n",
    "\n",
    "# add columns together\n",
    "adv_team_names_cleaned['sal_teams'] = sal_team_names_cleaned\n",
    "\n",
    "#Create join dataframe\n",
    "salary_df = salary_df.merge(years_df,how='inner',left_on='year',right_on='year_range')\n",
    "salary_df = salary_df[['slug', 'year_y','team', 'salary']]\n",
    "salary_df = salary_df.dropna()\n",
    "salary_df['year'] = salary_df['year_y'].astype(int)\n",
    "\n",
    "#Get experience\n",
    "adv_stats_exp = experience(adv_stats, names)\n",
    "\n",
    "#Add allstar data\n",
    "adv_stats_exp = adv_stats_exp.merge(all_stars,how='left', left_on=['name','year'], right_on=['player','year']).fillna(0)\n",
    "adv_stats_exp['allstar'] = adv_stats_exp['allstar'].astype(int)\n",
    "\n",
    "#Merge into final df\n",
    "adv_stats_final = adv_stats_exp.merge(salary_df[['slug','year','salary']], how='left', left_on=['slug','year'], right_on=['slug','year']).dropna()\n",
    "\n",
    "#data df\n",
    "data = adv_stats_final.drop(columns=['slug','name','year','player','min_year'])\n",
    "data['log_sal'] = np.log(data['salary'])\n",
    "data['exp^2']= np.square(data['exp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nresults = {}\\nresults['combos'] = []\\nresults['R2'] = []\\nresults['R2_adj'] = []\\nresults['RMSE'] = []\\ncount = 0\\ncategorical_variables=['positions','team']\\ndataframe=data\\nfor combo in combos_with_fixed:\\n\\n    X = dataframe[combo]\\n\\n    cat =[]\\n    for i in combo:\\n        if i in categorical_variables:\\n            cat.append(i)\\n\\n    if len(cat) >=1:\\n        X = pd.get_dummies(X, columns=cat, drop_first=True)\\n\\n\\n    X = sm.add_constant(X.values)\\n    res = sm.OLS(y,X).fit()\\n    mse = np.divide(np.sum(np.square(res.resid)),len(data['log_sal']))\\n    rmse = np.sqrt(mse)\\n\""
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables_to_test = ['positions', 'age', 'team', 'games_played', 'minutes_played',\n",
    "       'player_efficiency_rating', 'true_shooting_percentage',\n",
    "       'three_point_attempt_rate', 'free_throw_attempt_rate',\n",
    "       'offensive_rebound_percentage', 'defensive_rebound_percentage',\n",
    "       'total_rebound_percentage', 'assist_percentage', 'steal_percentage',\n",
    "       'block_percentage', 'turnover_percentage', 'usage_percentage',\n",
    "       'offensive_win_shares', 'defensive_win_shares', 'win_shares',\n",
    "       'win_shares_per_48_minutes', 'offensive_box_plus_minus',\n",
    "       'defensive_box_plus_minus', 'box_plus_minus',\n",
    "       'value_over_replacement_player', 'allstar']\n",
    "\n",
    "results, combos = linear_regression_combos(fixed_y=fixed_y, \n",
    "                         fixed_X=fixed_X,\n",
    "                         variables_to_test=variables_to_test,\n",
    "                         categorical_variables=['positions','team'],\n",
    "                         dataframe=data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
